<!DOCTYPE html>
<html>

<head lang="en">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>CoPoNeRF</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://ku-cvlab.github.io/CoPoNeRF/">
    <meta property="og:title" content="CoPoNeRF">
    <meta property="og:description" content="">

    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/codemirror.min.js"></script>
    <script src="js/clipboard.min.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/app.js"></script>
</head>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-QVFM103BVF"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-QVFM103BVF');
</script>

<body>
    <div class="container" id="header" style="text-align: center; margin: auto;">
        <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
            <h2 class="col-md-12 text-center" id="title">
                <b>CoPoNeRF</b>: Unifying Correspondence, Pose and NeRF for Pose-Free Novel View Synthesis from Stereo Pairs<br>
                <small>
                    Arxiv 2023
                </small>
            </h2>
        </div>
        <div class="row" id="author-row" style="margin:0 auto;">
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <a style="text-decoration:none" href="https://sunghwanhong.github.io/">
                    Sunghwan&nbsp;Hong<sup>1</sup>
                </a>
                <span style="padding-left: 20px;"></span>
                <a style="text-decoration:none" href="https://github.com/crepejung00">
                    Jaewoo&nbsp;Jung<sup>1</sup>
                </a>
                <span style="padding-left: 20px;"></span>
                <a style="text-decoration:none" href="https://github.com/hsshin98">
                    Heeseong&nbsp;Shin<sup>1</sup>
                </a>
                <br>
                <a style="text-decoration:none" href="https://jlyang.org/">
                    Jiaolong&nbsp;Yang<sup>2</sup>
                </a>
                <span style="padding-left: 20px;"></span>
                <a style="text-decoration:none" href="https://www.microsoft.com/en-us/research/people/cluo/?from=https://research.microsoft.com/en-us/people/cluo/&type=exact">
                    Seungryong&nbsp;Kim<sup>1</sup> 
                </a>
                <span style="padding-left: 20px;"></span>
                <a style="text-decoration:none" href="https://cvlab.korea.ac.kr">
                    Chong&nbsp;Luo<sup>2</sup>
                </a>
                <table class="author-table" id="author-table">
                    <tr>
                        <td>
                            <sup>1</sup>Korea University
                        </td>
                        <td>
                            <sup>2</sup>Microsoft Research Asia
                        </td>
                    </tr>
                </table>
            </div>
        </div>
    </div>
    <script>
        document.getElementById('author-row').style.maxWidth = document.getElementById("-row").clientWidth + 'px';
    </script>

    <div class="container" id="main">
        <div class="row">
            <div class="col-sm-6 col-sm-offset-3 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="">
                            <img src="./img/paper_image.png" height="60px">
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <!-- <li>
                            <a href="https://youtu.be/qrdRH9irAlk">
                            <img src="./img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li> -->
                    <!-- <li>
                            <a href="https://storage.googleapis.com/gresearch/refraw360/ref.zip" target="_blank">
                            <image src="img/database_icon.png" height="60px">
                                <h4><strong>Shiny Dataset</strong></h4>
                            </a>
                        </li>                          -->
                    <li>
                        <a href="https://github.com/KU-CVLAB/CoPoNeRF" target="_blank">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>
        <!-- <div class="container">
            <div class="row">
                <video class="video" id="kplanes" width="50%" loop playsinline muted controls
                    src="./img/kplanes_regnerf_ours.mp4"></video>
                <div class="text-center">
                    TBD.
                    <br><br>

                </div>
            </div>
        </div> -->

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Overview
                </h3>
                <div class="text-center">
                    <img src="./img/main_figure.png" width="100%">
                </div>
                <br>
                <div class="text-justify">
                    SE-NeRF utilizes the teacher-student framework to distill the knowledge of learned 3D geometry from
                    teacher to student. To do this, we apply a separate distillation scheme for reliable and unreliable
                    rays. The process is done in an iterative manner as the student becomes the new teacher.
                </div>
            </div>
        </div> -->

            
	<div class="container">   
            <div class="row">
		<div class="col-md-3">
		    <div>
			<video class="video" id="Teaser"  width="20%"  loop playsinline autoPlay muted src="./img/final0.mp4" onplay="resizeAndPlay(this)"></video>
			<canvas width="100" height="100" class="videoMerge" id="TeaserMerge"></canvas>
		    </div>
            	</div>
		<div class="col-md-3">
		    <div>
			<video class="video" id="0758"  width="20%"  loop playsinline autoPlay muted src="./img/final1.mp4" onplay="resizeAndPlay(this)"></video>
			<canvas width="100" height="100" class="videoMerge" id="0758Merge"></canvas>
		    </div>
            	</div>
        <div class="col-md-3">
            <div>
            <video class="video" id="0710d"  width="20%"  loop playsinline autoPlay muted src="./img/final2.mp4" onplay="resizeAndPlay(this)"></video>
            <canvas width="100" height="100" class="videoMerge" id="0710dMerge"></canvas>
            </div>
                </div>
        <div class="col-md-3">
            <div>
            <video class="video" id="0758d"  width="20%"  loop playsinline autoPlay muted src="./img/final3.mp4" onplay="resizeAndPlay(this)"></video>
            <canvas width="100" height="100" class="videoMerge" id="0758dMerge"></canvas>
            </div>
                </div>
            	</div>
            </div>
	</div>

	
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    This work delves into the task of pose-free novel view synthesis from stereo pairs, 
                    a challenging and pioneering task in 3D vision. Our innovative framework, unlike any before, 
                    seamlessly integrates 2D correspondence matching, camera pose estimation, and NeRF rendering, 
                    fostering a synergistic enhancement of these tasks. We achieve this through designing an architecture 
                    that utilizes a shared representation, which serves as a foundation for enhanced 3D geometry understanding. 
                    Capitalizing on the inherent interplay between the tasks, our unified framework is trained end-to-end with 
                    the proposed training strategy to improve overall model accuracy. Through extensive evaluations across 
                    diverse indoor and outdoor scenes from two real-world datasets, we demonstrate that our approach 
                    achieves substantial improvement over previous methodologies, especially in scenarios characterized 
                    by extreme viewpoint changes and the absence of accurate camera poses.
                </p>
            </div>
        </div>

        <div class="row">
            <!-- <div class="col-md-8 col-md-offset-2">
                <h3>
                    Methodology
                </h3>
                <div class="text-justify">
                    We distillize the knowledge of the teacher network to the student by applying <b>seperate
                        distillation schemes</b> for reliable and unreliable rays.
                    <div class="text-center">
                        <img src="./img/Distillation.png" width="100%">
                    </div>
                </div>
            </div> -->

            <div class="row">
                <div class="col-md-8 col-md-offset-2">
                    <h3>
                        Qualitative Results
                    </h3>
                    <!-- <div>
                        <div class="row">
                            <div class="col-md-4">
                                <video class="video" id="0758" width="33%" loop playsinline autoPlay muted
                                    src="./img/hotdog_360.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas width="150" height="150" class="videoMerge" id="0758Merge"></canvas>
                            </div>
                            <div class="col-md-4">
                                <video class="video" id="0781" width="33%" loop playsinline autoPlay muted
                                    src="./img/lego_360.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas width="150" height="150" class="videoMerge" id="0781Merge"></canvas>
                            </div>
                            <div class="col-md-4">
                                <video class="video" id="Teaser" width="33%" loop playsinline autoPlay muted
                                    src="./img/mic_360.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas width="150" height="150" class="videoMerge" id="TeaserMerge"></canvas>
                            </div>
                        </div>
                    </div>
                    <br> -->
                    <div class="text-justify">
                        Qualitative comparisions on <b>RealEstate10K</b> Dataset.
                    </div>
                    <div class="text-center">
                        <img src="./img/coponerf/qual_RealEstate.png" width="100%">
                    </div>
                    <div class="text-justify">
                        Qualitative comparisons on <b>ACID</b> Dataset.
                    </div>
                    <div class="text-center">
                        <img src="./img/coponerf/qual_acid.png" width="100%">
                    </div>
                    <div class="text-justify">
                        Visualization of epipolar lines from estimated poses.
                    </div>
                    <div class="text-center">
                        <img src="./img/coponerf/epipolar.png" width="100%">
                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-md-8 col-md-offset-2">
                    <h3>
                        Quantitative Results
                    </h3>
                    <div class="text-justify">
                        The best-performing results are presented in <b>bold</b>, gray color indicates methods not directly 
                        comparable; they are included for reference only.
                        We also specify the targeted task for each method. 
                        We evaluate the performance of our method on camera pose estimation and novel view synthesis.
                    
                    <div class="text-center">
                        <img src="./img/coponerf/Table_PSNR.png" width="80%">
                    </div>
                    <br>
                    <div class="text-left">
                        <img src="./img/coponerf/Table_pose_estimation.png" width="100%">
                    </div>
                </div>
            </div>

            <!-- <image src="img/architecture.png" class="img-responsive" alt="overview" width="60%" style="max-height: 450px;margin:auto;"> -->

            <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://youtube.com/embed/qrdRH9irAlk" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->

            <div class="row">
                <div class="col-md-8 col-md-offset-2">
                    <h3>
                        Main Architecture
                    </h3>
                    <div class="text-justify">
                        For a pair of images, we extract multi-level feature maps and construct 4D correlation maps 
                        at each level, encoding pixel pair similarities. These maps are refined for flow and pose 
                        estimation, and the renderer then uses the estimated pose and refined feature maps for color 
                        and depth computation.
                    </div>
                    <div class="text-center">
                        <img src="./img/coponerf/main_architecture.png" width="100%">
                    </div>
                    <!-- <div class="text-center">
                    <video id="refdir" width="40%" playsinline autoplay loop muted>
                        <source src="video/reflection_animation.mp4" type="video/mp4" />
                    </video>
                </div> -->
                </div>
            </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10">
                    <textarea id="bibtex" class="form-control" readonly>
@misc{hong2023unifying,
    title={Unifying Correspondence, Pose and NeRF for Pose-Free Novel View Synthesis from Stereo Pairs}, 
    author={Sunghwan Hong and Jaewoo Jung and Heeseong Shin and Jiaolong Yang and Seungryong Kim and Chong Luo},
    year={2023},
    eprint={2312.07246},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
                    </textarea>
                </div>
            </div>
        </div>

            <div class="row">
                <div class="col-md-8 col-md-offset-2">
                    <h3>
                        Acknowledgements
                    </h3>
                    <p class="text-justify">
                        <!-- We would like to thank Lior Yariv and Kai Zhang for helping us evaluate their methods, and Ricardo Martin-Brualla for helpful comments on our text. DV is supported by the National Science Foundation under Cooperative Agreement PHY-2019786 (an NSF AI Institute, <a href="http://iaifi.org">http://iaifi.org</a>) -->
                        <!-- <br> -->
                        The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a>.
                    </p>
                </div>
            </div>
        </div>


</body>

</html>
